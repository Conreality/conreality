#!/usr/bin/env python2.7
import numpy
import cv2
from conreality import ddk, sdk
from conreality.sdk.vision import Color, Image
from conreality.sdk.vision import RED_COLOR, GREEN_COLOR, BLUE_COLOR

CAMERA_WIDTH  = 640
CAMERA_HEIGHT = 480
WINDOW_WIDTH  = CAMERA_WIDTH
WINDOW_HEIGHT = CAMERA_HEIGHT
TERM_CRITERIA = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)

class Object(sdk.model.Object):
  def __init__(self, left=(-1, -1), right=(-1, -1), id=None):
    super(Object, self).__init__(id)
    self.left  = left
    self.right = right
    self.color = BLUE_COLOR
    self.roi_hist = None
  def is_valid(self):
    (x1, y1), (x2, y2) = self.left, self.right
    return x1 <> -1 and x2 <> -1 and y1 <> -1 and y2 <> -1
  def normalize(self):
    (x1, y1), (x2, y2) = self.left, self.right
    self.left, self.right = (min(x1, x2), min(y1, y2)), (max(x1, x2), max(y1, y2))
    return self
  def window(self):
    (x1, y1), (x2, y2) = self.left, self.right
    return (x1, y1, x2-x1, y2-y1)
  def draw(self, image, color, thickness=1):
    image.draw_rectangle(self.left, self.right, color, thickness)
  def __str__(self):
    return "Object({}, {})".format(self.left, self.right)

class ArgumentParser(ddk.ArgumentParser):
  def init(self):
    self.add_argument('-w', '--window', action='store_true', help='enable GUI window')
    self.add_argument('input', nargs='?', default=0, help='input video stream (default: /dev/video0)')

class Driver(ddk.Driver):
  def has_window(self):
    return self.options.window

  def init(self):
    if self.has_window():
      cv2.namedWindow('Conreality')
      cv2.imshow('Conreality', Image(height=WINDOW_HEIGHT, width=WINDOW_WIDTH).data)
    self.open_camera()
    self.frame_count = 0 # the number of video frames processed
    self.frame = None    # the current video frame being processed
    self.object = None   # the current object being designated (if any)
    self.objects = []    # the current set of tracked objects

  def exit(self):
    self.camera.release()
    if self.has_window():
      cv2.destroyAllWindows()

  def loop(self):
    if self.has_window():
      cv2.setMouseCallback('Conreality', self.handle_mouse)
    while self.camera.isOpened():
      success, frame = self.camera.read()
      if not success:
        if not self.frame_count:
          self.error("Failed to read frame from video capture device; terminating...")
        break # end of video stream
      self.frame = Image(data=frame)
      self.frame_count += 1
      frame = None
      image = self.process_frame(self.frame)
      if self.has_window():
        cv2.imshow('Conreality', image.data)
        cv2.waitKey(1)
      else:
        self.pause() # TODO
    return self.frame_count

  def open_camera(self):
    self.camera = cv2.VideoCapture(self.video_source())
    #self.camera.set(cv2.cv.CV_CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
    #self.camera.set(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
    #self.camera.set(cv2.cv.CV_CAP_PROP_FPS, 30)
    return self.camera

  def video_source(self):
    if self.options.input:
      return self.options.input
    return 0 # the default camera

  def track_object(self, object):
    self.info("Tracking new designated object: {}", object)
    self.objects.append(object)
    object.normalize()
    (x1, y1), (x2, y2) = object.left, object.right
    roi = Image(data=self.frame.data[y1:y2, x1:x2])
    roi_hsv = roi.to_hsv()
    mask = cv2.inRange(roi_hsv.data, numpy.array((0., 60., 32.)), numpy.array((180., 255., 255.)))
    roi_hist = cv2.calcHist([roi_hsv.data], [0], mask, [180], [0, 180])
    cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)
    object.roi_hist = roi_hist

  def process_frame(self, frame):
    image = frame.copy()
    #image = frame.gray() # convert to grayscale

    for object in self.objects:
      hsv = frame.to_hsv()
      dst = cv2.calcBackProject([hsv.data], [0], object.roi_hist, [0, 180], 1)
      track_window = object.window()
      _, track_window = cv2.meanShift(dst, track_window, TERM_CRITERIA)
      x, y, w, h = track_window
      object.left, object.right = (x, y), (x + w, y + h)
      object.draw(image, object.color)

    if self.object and self.object.is_valid():
      self.object.draw(image, RED_COLOR)

    return image

  def handle_mouse(self, event, x, y, flags, param):
    #print (event, x, y, flags, param) # DEBUG
    if event == cv2.EVENT_LBUTTONDOWN:
      self.object = Object((x, y))
    elif event == cv2.EVENT_MOUSEMOVE:
      if self.object:
        self.object.right = (x, y)
    elif event == cv2.EVENT_LBUTTONUP:
      if self.object and self.object.is_valid():
        self.track_object(self.object)
      self.object = None

if __name__ == '__main__':
  Driver(argparser=ArgumentParser).run()
