#!/usr/bin/env python2.7
from conreality import ddk, sdk
from conreality.sdk.vision import Image, RED_COLOR, GREEN_COLOR, BLUE_COLOR
import cv2

CAMERA_WIDTH  = 640
CAMERA_HEIGHT = 480
WINDOW_WIDTH  = CAMERA_WIDTH
WINDOW_HEIGHT = CAMERA_HEIGHT
TERM_CRITERIA = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)

class Object(sdk.model.Object):
  def __init__(self, x, y, w, h, id=None, color=BLUE_COLOR):
    super(Object, self).__init__(id=id, color=color)
    # These properties apply only to the local camera's FOV:
    self.bounds = (x, y, w, h)
    self.histogram = None

  def draw(self, image, color=None, thickness=1):
    (x, y, w, h) = self.bounds
    image.draw_rectangle((x, y), (x+w, y+h), color or self.color, thickness)

  def __repr__(self):
    return "Object(x={}, y={}, w={}, h={})".format(*self.bounds)

class ArgumentParser(ddk.ArgumentParser):
  def init(self):
    self.add_argument('-w', '--window', action='store_true', help='enable GUI window')
    self.add_argument('input', nargs='?', default=0, help='input video stream (default: /dev/video0)')

class Driver(ddk.Driver):
  def has_window(self):
    return self.options.window

  def init(self):
    if self.has_window():
      cv2.namedWindow('Conreality')
      cv2.imshow('Conreality', Image(height=WINDOW_HEIGHT, width=WINDOW_WIDTH).data)
    self.open_camera()
    self.frame_count = 0       # the number of video frames processed
    self.frame = None          # the current video frame being processed
    self.designated_box = None # the current object being designated (if any)
    self.tracked_objects = []  # the current set of tracked objects

  def exit(self):
    self.camera.release()
    if self.has_window():
      cv2.destroyAllWindows()

  def loop(self):
    if self.has_window():
      cv2.setMouseCallback('Conreality', self.handle_mouse)
    while self.camera.isOpened():
      success, frame = self.camera.read()
      if not success:
        if not self.frame_count:
          self.error("Failed to read frame from video capture device; terminating...")
        break # end of video stream
      self.frame = Image(data=frame)
      self.frame_count += 1
      frame = None
      image = self.process_frame(self.frame)
      if self.has_window():
        cv2.imshow('Conreality', image.data)
        cv2.waitKey(1)
      else:
        self.pause() # TODO
    return self.frame_count

  def open_camera(self):
    self.camera = cv2.VideoCapture(self.video_source())
    #self.camera.set(cv2.cv.CV_CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
    #self.camera.set(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
    #self.camera.set(cv2.cv.CV_CAP_PROP_FPS, 30)
    return self.camera

  def video_source(self):
    if self.options.input:
      return self.options.input
    return 0 # the default camera

  def track_object(self, (x1, y1), (x2, y2)):
    (x1, y1), (x2, y2) = (min(x1, x2), min(y1, y2)), (max(x1, x2), max(y1, y2))

    object = Object(x1, y1, x2-x1, y2-y1)
    object.histogram = Image(data=self.frame.data[y1:y2, x1:x2]).histogram()

    self.info("Tracking new designated object: {}", object)
    self.tracked_objects.append(object)

  def process_frame(self, frame):
    image = frame.copy()
    #image = frame.gray() # convert to grayscale

    frame_hsv = frame.to_hsv()
    for object in self.tracked_objects:
      dst = cv2.calcBackProject([frame_hsv.data], [0], object.histogram, [0, 180], 1)
      old_bounds = object.bounds
      _, new_bounds = cv2.meanShift(dst, old_bounds, TERM_CRITERIA)
      object.bounds = new_bounds
      if new_bounds <> old_bounds:
        pass # TODO: output object movement message

    for object in self.tracked_objects:
      object.draw(image)

    if self.designated_box:
      p1, p2 = self.designated_box
      if p1 is not None and p2 is not None:
        image.draw_rectangle(p1, p2, RED_COLOR)

    return image

  def handle_mouse(self, event, x, y, flags, param):
    #print (event, x, y, flags, param) # DEBUG
    if event == cv2.EVENT_LBUTTONDOWN:
      self.designated_box = ((x, y), None)

    elif event == cv2.EVENT_MOUSEMOVE:
      if self.designated_box:
        p1, _ = self.designated_box
        self.designated_box = (p1, (x, y))

    elif event == cv2.EVENT_LBUTTONUP:
      if self.designated_box:
        p1, p2 = self.designated_box
        self.designated_box = None
        if p1 is not None and p2 is not None:
          self.track_object(p1, p2)

if __name__ == '__main__':
  Driver(argparser=ArgumentParser).run()
