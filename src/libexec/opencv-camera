#!/usr/bin/env python2.7
from conreality import ddk, sdk
from conreality.sdk.vision import Image, SharedImage, RED_COLOR, BLUE_COLOR
import cv2

CAMERA_WIDTH  = 640
CAMERA_HEIGHT = 480
WINDOW_WIDTH  = CAMERA_WIDTH
WINDOW_HEIGHT = CAMERA_HEIGHT
TERM_CRITERIA = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)

class Object(sdk.model.Object):
  def __init__(self, x, y, w, h, id=None, color=BLUE_COLOR):
    super(Object, self).__init__(id=id, color=color)
    # These properties apply only to the local camera's FOV:
    self.bounds = (x, y, w, h)
    self.histogram = None

  def draw(self, image, color=None, thickness=1):
    (x, y, w, h) = self.bounds
    image.draw_rectangle((x, y), (x+w, y+h), color or self.color, thickness)

  def __repr__(self):
    return "Object(x={}, y={}, w={}, h={})".format(*self.bounds)

class ArgumentParser(ddk.ArgumentParser):
  def init(self):
    self.add_argument('-w', '--window', action='store_true', help='show GUI window')
    self.add_argument('input', nargs='?', default=0, help='input for raw video stream (default: /dev/video0)')
    self.add_argument('output', nargs='?', default=0, help='output for current annotated frame (default: /dev/null)')

class Driver(ddk.Driver):
  def has_window(self):
    return self.options.window

  def init(self):
    if self.has_window():
      cv2.namedWindow('Conreality')
      cv2.imshow('Conreality', Image(height=WINDOW_HEIGHT, width=WINDOW_WIDTH).data)

    self.camera = self.open_camera()
    self.image_output = self.open_image_output()
    self.frame_count = 0       # the number of video frames processed
    self.frame = None          # the current video frame being processed
    self.designated_box = None # the current object being designated (if any)
    self.tracked_objects = []  # the current set of tracked objects

  def exit(self):
    self.camera.release()
    if self.has_window():
      cv2.destroyAllWindows()

  def loop(self):
    if self.has_window():
      cv2.setMouseCallback('Conreality', self.handle_mouse)

    while self.camera.isOpened():
      success, frame = self.camera.read()
      if not success:
        if not self.frame_count:
          self.error("Failed to read frame from video capture device; terminating...")
        break # end of video stream

      self.frame = Image(data=frame)
      self.frame_count += 1
      frame = None
      image = self.process_frame(self.frame)

      if self.image_output:
        image.copy_to(self.image_output)

      if self.has_window():
        cv2.imshow('Conreality', image.data)
        cv2.waitKey(1)

    return self.frame_count

  def open_camera(self):
    camera = cv2.VideoCapture(self.video_source())
    #camera.set(cv2.cv.CV_CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
    #camera.set(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
    #camera.set(cv2.cv.CV_CAP_PROP_FPS, 30)
    return camera

  def open_image_output(self):
    image_target = self.image_target()
    if image_target:
      try:
        return SharedImage(image_target, mode='r+', width=CAMERA_WIDTH, height=CAMERA_HEIGHT)
      except IOError:
        return SharedImage(image_target, mode='w+', width=CAMERA_WIDTH, height=CAMERA_HEIGHT)
    return None

  def video_source(self):
    if self.options.input and self.options.input <> '-':
      return self.options.input
    return 0 # the default camera

  def image_target(self):
    if self.options.output:
      return self.options.output
    return None

  def track_object(self, (x1, y1), (x2, y2)):
    (x1, y1), (x2, y2) = (min(x1, x2), min(y1, y2)), (max(x1, x2), max(y1, y2))

    object = Object(x1, y1, x2-x1, y2-y1)
    object.histogram = Image(data=self.frame.data[y1:y2, x1:x2]).histogram()

    self.info("Tracking new designated object: {}", object)
    self.tracked_objects.append(object)

  def process_frame(self, frame):
    frame_hsv = frame.to_hsv()

    for object in self.tracked_objects:
      dst = cv2.calcBackProject([frame_hsv.data], [0], object.histogram, [0, 180], 1)
      old_bounds = object.bounds
      _, new_bounds = cv2.meanShift(dst, old_bounds, TERM_CRITERIA)
      object.bounds = new_bounds
      if new_bounds <> old_bounds:
        pass # TODO: output object movement message

    image = frame.copy()
    for object in self.tracked_objects:
      object.draw(image)
    if self.designated_box:
      p1, p2 = self.designated_box
      if p1 is not None and p2 is not None:
        image.draw_rectangle(p1, p2, RED_COLOR)
    return image

  def handle_mouse(self, event, x, y, flags, param):
    #print (event, x, y, flags, param) # DEBUG
    if event == cv2.EVENT_LBUTTONDOWN:
      self.designated_box = ((x, y), None)

    elif event == cv2.EVENT_MOUSEMOVE:
      if self.designated_box:
        p1, _ = self.designated_box
        self.designated_box = (p1, (x, y))

    elif event == cv2.EVENT_LBUTTONUP:
      if self.designated_box:
        p1, p2 = self.designated_box
        self.designated_box = None
        if p1 is not None and p2 is not None:
          self.track_object(p1, p2)

if __name__ == '__main__':
  Driver(argparser=ArgumentParser).run()
