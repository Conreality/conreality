#!/usr/bin/env python3
# This is free and unencumbered software released into the public domain.

import os, sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', 'python')))

from conreality import ddk, sdk
from conreality.sdk.vision import BLUE_COLOR, GREEN_COLOR, RED_COLOR
from datetime import datetime
import cv2

WINDOW_TITLE  = 'OpenCV Object Tracking'

TERM_CRITERIA = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)
FACE_CASCADE  = sdk.vision.CascadeClassifier('haarcascade_frontalface_default.xml')
EYE_CASCADE   = sdk.vision.CascadeClassifier('haarcascade_eye_tree_eyeglasses.xml')

class Object(sdk.model.Object):
  def __init__(self, x, y, w, h, id=None, color=BLUE_COLOR):
    super(Object, self).__init__(id=id, color=color)
    # These properties apply only to the local camera's FOV:
    self.bounds = (x, y, w, h)
    self.histogram = None

  def draw(self, image, color=None, thickness=1):
    (x, y, w, h) = self.bounds
    image.draw_rectangle((x, y), (x+w, y+h), color or self.color, thickness)

  def __repr__(self):
    return "Object(x={}, y={}, w={}, h={})".format(*self.bounds)

class Driver(ddk.Driver):
  """Driver for OpenCV object tracking."""

  class ArgumentParser(ddk.ArgumentParser):
    def init(self):
      self.add_argument('id', nargs='?', default='default',
        help='the ID of the camera to attach to')
      self.add_argument('-I', '--id', metavar='ID', nargs='?',
        help='set camera ID (default: default)')
      self.add_argument('-o', '--output', metavar='FILE', nargs='?',
        help='record output to MPEG-4 video file')
      self.add_argument('-a', '--algorithm', metavar='ALGO', nargs=1, default='meanshift',
        help='set object-tracking algorithm (default: meanshift)')
      self.add_argument('-w', '--window', action='store_true',
        help='show GUI window')

  def init(self):
    self.context.define('object', {'designate': self.designate_object})

    self.camera_id = self.options.id or 'default'
    self.camera_dir = ddk.camera.CameraDirectory(self.camera_id).open('r')
    self.input_feed = self.camera_dir.open_feed(channel='original')
    self.output_feed = self.camera_dir.open_feed(size=self.input_feed.size, channel='objtrack', mode='w+')

    self.frame_count = 0       # the number of video frames processed
    self.frame = None          # the current video frame being processed
    self.designated_box = None # the current object being designated (if any)
    self.tracked_objects = []  # the current set of tracked objects
    self.tracked_faces = []
    self.tracked_eyes = []

    self.video_output = None
    if self.options.output:
      self.video_output = sdk.video.VideoEncoder(self.options.output, self.input_feed.size)

    if self.has_window:
      self.window_title = '{} ({})'.format(WINDOW_TITLE, self.camera_id)
      self.window_width = self.input_feed.width
      self.window_height = self.input_feed.height
      cv2.namedWindow(self.window_title, cv2.WINDOW_AUTOSIZE)
      cv2.imshow(self.window_title, sdk.vision.Image(width=self.window_width, height=self.window_height).data)
      cv2.setMouseCallback(self.window_title, self.handle_mouse)

  def exit(self):
    if self.video_output:
      self.video_output.close()

    if self.has_window:
      cv2.destroyAllWindows()

  def loop(self):
    self.frame = self.input_feed.snap('bgr')
    self.frame_count += 1

    image = self.process_frame(self.frame)

    if self.output_feed:
      image.copy_to(self.output_feed.image)

    if self.video_output:
      self.video_output.write(image)

    if self.has_window:
      cv2.imshow(self.window_title, image.data)
      key = cv2.waitKey(1)
      if key == 0x1B: # ESC
        self.stop()

    return self.frame_count

  def track_object(self, p1, p2, id=None):
    (x1, y1), (x2, y2) = p1, p2
    (x1, y1), (x2, y2) = (min(x1, x2), min(y1, y2)), (max(x1, x2), max(y1, y2))
    object = Object(x1, y1, x2-x1, y2-y1)
    object.histogram = sdk.vision.Image(data=self.frame.data[y1:y2, x1:x2]).histogram()
    self.info("Tracking new designated object: {}", object)
    self.tracked_objects.append(object)

  def designate_object(self, args):
    x, y, w, h, id = args.x, args.y, args.w, args.h, args.id
    if not x or not y or not w or not h:
      raise sdk.scripting.Error("missing x, y, w, or h attribute")
    self.track_object((x, y), (x+w, y+h), id)

  def compute_meanshift(self, frame_hsv, object):
    old_bounds = object.bounds
    dst = cv2.calcBackProject([frame_hsv.data], [0], object.histogram, [0, 180], 1)
    _, new_bounds = cv2.meanShift(dst, old_bounds, TERM_CRITERIA)
    return new_bounds

  def process_frame(self, frame):
    frame_hsv = frame.to_hsv()
    frame_gray = frame.to_gray()

    # Track objects:
    for object in self.tracked_objects:
      old_bounds = object.bounds
      new_bounds = self.compute_meanshift(frame_hsv, object)
      if new_bounds != old_bounds:
        object.bounds = new_bounds
        pass # TODO: emit object movement message

    # Detect faces:
    if FACE_CASCADE:
      self.tracked_faces = FACE_CASCADE.detect(frame_gray, 1.3, 5) or self.tracked_faces

    # Detect eyes in faces:
    if EYE_CASCADE and self.tracked_faces:
      eyes = []
      for (fx, fy, fw, fh) in self.tracked_faces:
        roi = sdk.vision.Image(data=frame_gray.data[fy:fy+fh, fx:fx+fw], format='gray')
        for (ex, ey, ew, eh) in EYE_CASCADE.detect(roi):
          eyes.append((fx+ex, fy+ey, ew, eh))
      if eyes:
        self.tracked_eyes = eyes

    image = frame.copy()

    for object in self.tracked_objects:
      object.draw(image)

    for (x, y, w, h) in self.tracked_faces:
      image.draw_rectangle((x, y), (x+w, y+h), GREEN_COLOR)

    for (x, y, w, h) in self.tracked_eyes:
      image.draw_rectangle((x, y), (x+w, y+h), GREEN_COLOR)

    if self.designated_box:
      p1, p2 = self.designated_box
      if p1 is not None and p2 is not None:
        image.draw_rectangle(p1, p2, RED_COLOR)

    image.draw_text((12, -12), self.camera_id, GREEN_COLOR)
    image.draw_text((-12, -12), datetime.now().isoformat()[:-3], GREEN_COLOR)
    return image

  def handle_mouse(self, event, x, y, flags, param):
    if event == cv2.EVENT_LBUTTONDOWN:
      self.designated_box = ((x, y), None)

    elif event == cv2.EVENT_MOUSEMOVE:
      if self.designated_box:
        p1, _ = self.designated_box
        self.designated_box = (p1, (x, y))

    elif event == cv2.EVENT_LBUTTONUP:
      if self.designated_box:
        p1, p2 = self.designated_box
        self.designated_box = None
        if p1 is not None and p2 is not None:
          self.track_object(p1, p2)

if __name__ == '__main__':
  import sys
  with Driver(argparser=Driver.ArgumentParser) as driver:
    sys.exit(driver.run())
