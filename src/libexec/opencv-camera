#!/usr/bin/env python2.7
from conreality import ddk, sdk
from conreality.sdk.vision import Image, SharedImage, RED_COLOR, GREEN_COLOR, BLUE_COLOR
from datetime import datetime
import cv2

CAMERA_WIDTH  = 640
CAMERA_HEIGHT = 480
WINDOW_WIDTH  = CAMERA_WIDTH
WINDOW_HEIGHT = CAMERA_HEIGHT
WINDOW_TITLE  = 'OpenCV Camera'
TERM_CRITERIA = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)

class Object(sdk.model.Object):
  def __init__(self, x, y, w, h, id=None, color=BLUE_COLOR):
    super(Object, self).__init__(id=id, color=color)
    # These properties apply only to the local camera's FOV:
    self.bounds = (x, y, w, h)
    self.histogram = None

  def draw(self, image, color=None, thickness=1):
    (x, y, w, h) = self.bounds
    image.draw_rectangle((x, y), (x+w, y+h), color or self.color, thickness)

  def __repr__(self):
    return "Object(x={}, y={}, w={}, h={})".format(*self.bounds)

class ArgumentParser(ddk.ArgumentParser):
  def init(self):
    self.add_argument('input', nargs='?', default=0,
      help='the video feed input (default: /dev/video0)')
    self.add_argument('-i', '--id', metavar='ID', nargs='?',
      help='set camera ID (default: default)')
    self.add_argument('-o', '--output', metavar='FILE', nargs='?',
      help='record output to MPEG-4 video file')
    self.add_argument('-a', '--algorithm', metavar='ALGO', nargs=1, default='meanshift',
      help='set object-tracking algorithm (default: meanshift)')
    self.add_argument('-w', '--window', action='store_true',
      help='show GUI window')

class Driver(ddk.Driver):
  def has_window(self):
    return self.options.window

  def init(self):
    self.camera = self.open_camera()
    self.camera_id = self.options.id or 'default'
    self.camera_dir = ddk.CameraDirectory(self.camera_id).open('w')
    self.camera_feed = self.camera_dir.open_feed(width=CAMERA_WIDTH, height=CAMERA_HEIGHT, mode='w+')
    self.frame_count = 0       # the number of video frames processed
    self.frame = None          # the current video frame being processed
    self.designated_box = None # the current object being designated (if any)
    self.tracked_objects = []  # the current set of tracked objects

    if self.options.output:
      self.video_output = sdk.video.VideoEncoder(self.options.output, self.camera_feed.size)

    if self.has_window():
      self.window_title = '{} ({})'.format(WINDOW_TITLE, self.camera_id)
      cv2.namedWindow(self.window_title)
      cv2.imshow(self.window_title, Image(height=WINDOW_HEIGHT, width=WINDOW_WIDTH).data)

  def exit(self):
    self.camera.release()
    self.video_output.close()

    if self.has_window():
      cv2.destroyAllWindows()

  def loop(self):
    if self.has_window():
      cv2.setMouseCallback(self.window_title, self.handle_mouse)

    while self.camera.isOpened():
      success, frame = self.camera.read()
      if not success:
        if not self.frame_count:
          self.error("Failed to read frame from video capture device; terminating...")
        break # end of video stream

      self.frame = Image(data=frame)
      self.frame_count += 1
      frame = None
      image = self.process_frame(self.frame)

      if self.camera_feed:
        image.copy_to(self.camera_feed.image)

      if self.video_output:
        self.video_output.write(image)

      if self.has_window():
        cv2.imshow(self.window_title, image.data)
        key = cv2.waitKey(1)
        if key == 0x1B: # ESC
          break

    return self.frame_count

  def open_camera(self):
    camera = cv2.VideoCapture(self.video_source())
    #camera.set(cv2.cv.CV_CAP_PROP_FRAME_WIDTH, CAMERA_WIDTH)
    #camera.set(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT, CAMERA_HEIGHT)
    #camera.set(cv2.cv.CV_CAP_PROP_FPS, 30)
    return camera

  def video_source(self):
    if self.options.input and self.options.input <> '-':
      return self.options.input
    return 0 # the default camera

  def track_object(self, (x1, y1), (x2, y2)):
    (x1, y1), (x2, y2) = (min(x1, x2), min(y1, y2)), (max(x1, x2), max(y1, y2))

    object = Object(x1, y1, x2-x1, y2-y1)
    object.histogram = Image(data=self.frame.data[y1:y2, x1:x2]).histogram()

    self.info("Tracking new designated object: {}", object)
    self.tracked_objects.append(object)

  def compute_meanshift(self, frame_hsv, object):
    old_bounds = object.bounds
    dst = cv2.calcBackProject([frame_hsv.data], [0], object.histogram, [0, 180], 1)
    _, new_bounds = cv2.meanShift(dst, old_bounds, TERM_CRITERIA)
    return new_bounds

  def process_frame(self, frame):
    frame_hsv = frame.to_hsv()
    for object in self.tracked_objects:
      old_bounds = object.bounds
      new_bounds = self.compute_meanshift(frame_hsv, object)
      if new_bounds <> old_bounds:
        object.bounds = new_bounds
        pass # TODO: emit object movement message

    image = frame.copy()
    for object in self.tracked_objects:
      object.draw(image)
    if self.designated_box:
      p1, p2 = self.designated_box
      if p1 is not None and p2 is not None:
        image.draw_rectangle(p1, p2, RED_COLOR)

    image.draw_text((12, -12), self.camera_id, GREEN_COLOR)
    image.draw_text((-12, -12), datetime.now().isoformat()[:-3], GREEN_COLOR)
    return image

  def handle_mouse(self, event, x, y, flags, param):
    if event == cv2.EVENT_LBUTTONDOWN:
      self.designated_box = ((x, y), None)

    elif event == cv2.EVENT_MOUSEMOVE:
      if self.designated_box:
        p1, _ = self.designated_box
        self.designated_box = (p1, (x, y))

    elif event == cv2.EVENT_LBUTTONUP:
      if self.designated_box:
        p1, p2 = self.designated_box
        self.designated_box = None
        if p1 is not None and p2 is not None:
          self.track_object(p1, p2)

if __name__ == '__main__':
  Driver(argparser=ArgumentParser).run()
